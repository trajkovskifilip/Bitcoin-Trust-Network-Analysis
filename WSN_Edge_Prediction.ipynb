{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WSN_Edge_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpq4u76sV0D0",
        "outputId": "8a31880d-6980-48b3-9b61-4eaa516b501d"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsVZpQZzVm0W"
      },
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5N3JUJYVuwk"
      },
      "source": [
        "class Fairness_Goodness():\n",
        "    def __init__(self, G):\n",
        "        fairness, goodness = self.initialize_scores(G)\n",
        "\n",
        "        nodes = G.nodes()\n",
        "        iter = 0\n",
        "        while iter < 100:\n",
        "            df = 0\n",
        "            dg = 0\n",
        "\n",
        "            # print('-----------------')\n",
        "            # print(\"Iteration number\", iter)\n",
        "\n",
        "            # print('Updating goodness')\n",
        "            for node in nodes:\n",
        "                inedges = G.in_edges(node, data='weight')\n",
        "                g = 0\n",
        "                for edge in inedges:\n",
        "                    g += fairness[edge[0]] * edge[2]\n",
        "\n",
        "                try:\n",
        "                    dg += abs(g / len(inedges) - goodness[node])\n",
        "                    goodness[node] = g / len(inedges)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            # print('Updating fairness')\n",
        "            for node in nodes:\n",
        "                outedges = G.out_edges(node, data='weight')\n",
        "                f = 0\n",
        "                for edge in outedges:\n",
        "                    f += 1.0 - abs(edge[2] - goodness[edge[1]]) / 2.0\n",
        "\n",
        "                try:\n",
        "                    df += abs(f / len(outedges) - fairness[node])\n",
        "                    fairness[node] = f / len(outedges)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            # print('Differences in fairness score = %.6f and goodness score = %.6f' % (df, dg))\n",
        "            if df < math.pow(10, -6) and dg < math.pow(10, -6):\n",
        "                break\n",
        "            iter += 1\n",
        "\n",
        "        self.fairness = fairness\n",
        "        self.goodness = goodness\n",
        "\n",
        "    def initialize_scores(self, G):\n",
        "        fairness = {}\n",
        "        goodness = {}\n",
        "\n",
        "        nodes = G.nodes()\n",
        "        for node in nodes:\n",
        "            fairness[node] = 1\n",
        "            try:\n",
        "                goodness[node] = G.in_degree(node, weight='weight') * 1.0 / G.in_degree(node)\n",
        "            except:\n",
        "                goodness[node] = 0\n",
        "        return fairness, goodness\n",
        "\n",
        "    def compute_fairness_goodness(self, G):\n",
        "        return self.fairness, self.goodness\n",
        "\n",
        "    def predict_weight(self, u, v):\n",
        "        pred_w = self.fairness[u] * self.goodness[v]\n",
        "        return pred_w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZMfmhJGW4fb"
      },
      "source": [
        "class Reciprocal():\n",
        "    def __init__(self, G):\n",
        "        self.G = G\n",
        "\n",
        "    def predict_weight(self, u, v):\n",
        "        if self.G.has_edge(v, u):\n",
        "            return self.G[v][u]['weight']\n",
        "        else:\n",
        "            return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6k7vhQdXLd0"
      },
      "source": [
        "class Bias_Deserve():\n",
        "\n",
        "    def __init__(self, G):\n",
        "\n",
        "        bias, des = self.initialize_scores(G)\n",
        "\n",
        "        nodes = G.nodes()\n",
        "        iter = 0\n",
        "        while iter < 100:\n",
        "            db = 0\n",
        "            dd = 0\n",
        "\n",
        "            # print('-----------------')\n",
        "            # print(\"Iteration number\", iter)\n",
        "\n",
        "            # print('Updating des')\n",
        "            for node in nodes:\n",
        "                inedges = G.in_edges(node, data='weight')\n",
        "                d = 0\n",
        "                for edge in inedges:\n",
        "                    X = max(0, bias[edge[0]] * edge[2])\n",
        "                    d += edge[2] * (1 - X)\n",
        "                try:\n",
        "                    dd += abs(d / len(inedges) - des[node])\n",
        "                    des[node] = d / len(inedges)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            # print('Updating bias')\n",
        "            for node in nodes:\n",
        "                outedges = G.out_edges(node, data='weight')\n",
        "                b = 0\n",
        "                for edge in outedges:\n",
        "                    b += (edge[2] - des[edge[1]]) / 2.0\n",
        "                try:\n",
        "                    db += abs(b / len(outedges) - bias[node])\n",
        "                    bias[node] = b / len(outedges)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            # print('Differences in bias score = %.6f and des score = %.6f' % (db, dd))\n",
        "            if db < math.pow(10, -6) and dd < math.pow(10, -6):\n",
        "                break\n",
        "            iter += 1\n",
        "\n",
        "        self.bias = bias\n",
        "        self.des = des\n",
        "\n",
        "    def initialize_scores(self, G):\n",
        "        des = {}\n",
        "        bias = {}\n",
        "        nodes = G.nodes()\n",
        "        for node in nodes:\n",
        "            bias[node] = 1\n",
        "            try:\n",
        "                des[node] = G.in_degree(node, weight='weight') * (1.0 - max(0, bias[node] * G.in_degree(node, weight='weight'))) / G.in_degree(node)\n",
        "            except:\n",
        "                des[node] = 0\n",
        "        return bias, des\n",
        "    \n",
        "    def compute_bias_des(self, G):\n",
        "        return self.bias, self.des\n",
        "\n",
        "    def predict_weight(self, u, v):\n",
        "        return self.des[v]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXV1Z8Ima5Tl"
      },
      "source": [
        "def signed_hits(G, max_iter=100, tol=1.0e-8, normalized=True):\n",
        "\n",
        "    if type(G) == nx.MultiGraph or type(G) == nx.MultiDiGraph:\n",
        "        raise Exception(\"hits() not defined for graphs with multiedges.\")\n",
        "    if len(G) == 0:\n",
        "        return {}, {}\n",
        "    # choose fixed starting vector if not given\n",
        "\n",
        "    h_p = dict.fromkeys(G, 1.0 / G.number_of_nodes())\n",
        "    h_n = dict.fromkeys(G, - 1.0 / G.number_of_nodes())\n",
        "    h = h_p\n",
        "    a = h_p\n",
        "    for _ in range(max_iter):  # power iteration: make up to max_iter iterations\n",
        "        h_p_last = h_p\n",
        "        h_n_last = h_n\n",
        "\n",
        "        h_p = dict.fromkeys(h_p_last.keys(), 0)\n",
        "        h_n = dict.fromkeys(h_n_last.keys(), 0)\n",
        "        a_p = dict.fromkeys(h_p_last.keys(), 0)\n",
        "        a_n = dict.fromkeys(h_n_last.keys(), 0)\n",
        "\n",
        "        # this \"matrix multiply\" looks odd because it is\n",
        "        # doing a left multiply a^T=hlast^T*G\n",
        "\n",
        "        for u in h_p:\n",
        "            for v in G.pred[u]:\n",
        "                if G[v][u]['weight'] >= 0 :\n",
        "                    a_p[u] += h_p_last[v] * G[v][u]['weight']\n",
        "                else :\n",
        "                    a_n[u] -= h_n_last[v] * G[v][u]['weight']\n",
        "        for u in h_p:\n",
        "            for v in G.succ[u]:\n",
        "                if G[u][v]['weight'] >= 0:\n",
        "                    h_p[u] += a_p[v] * G[u][v]['weight']\n",
        "                else :\n",
        "                    h_n[u] -= a_n[v] * G[u][v]['weight']\n",
        "\n",
        "\n",
        "        # normalize vector\n",
        "        s = 1.0 / max(h_p.values())\n",
        "        for n in h_p:\n",
        "            h_p[n] *= s\n",
        "        # normalize vector\n",
        "        s = -1.0 / min(h_n.values())\n",
        "        for n in h_n:\n",
        "            h_n[n] *= s\n",
        "        # normalize vector\n",
        "        s = 1.0 / max(a_p.values())\n",
        "        for n in a_p:\n",
        "            a_p[n] *= s\n",
        "        # normalize vector\n",
        "        s = -1.0 / min(a_n.values())\n",
        "        for n in a_n:\n",
        "            a_n[n] *= s\n",
        "\n",
        "        for key, value in h.items():\n",
        "            h[key] = h_p[key] - h_n[key]\n",
        "            a[key] = a_p[key] - a_n[key]\n",
        "\n",
        "        # check convergence, l1 norm\n",
        "        err = sum([abs(h_p[n] - h_p_last[n]) for n in h_p] + [abs(h_n[n] - h_n_last[n]) for n in h_n] )\n",
        "        if err < tol:\n",
        "            break\n",
        "    else:\n",
        "        raise nx.PowerIterationFailedConvergence(max_iter)\n",
        "    if normalized:\n",
        "        s = 1.0 / sum(a.values())\n",
        "        for n in a:\n",
        "            a[n] *= s\n",
        "        s = 1.0 / sum(h.values())\n",
        "        for n in h:\n",
        "            h[n] *= s\n",
        "    return h, a\n",
        "\n",
        "class Signed_Hits():\n",
        "    def __init__(self, G):\n",
        "        self.G = G\n",
        "        h, a = signed_hits(G, max_iter=500)\n",
        "        G_hits = self.G.copy()\n",
        "        w_in = {}\n",
        "        w_out = {}\n",
        "        Hits_total_out = {}\n",
        "        Hits_total_in = {}\n",
        "\n",
        "        for (u, w) in G_hits.nodes(data='weight'):\n",
        "            w_in_v = 0\n",
        "            w_out_v = 0\n",
        "            Hits_total_out_v = 0\n",
        "            Hits_total_in_v = 0\n",
        "            for edge in G_hits.out_edges(u, data='weight'):\n",
        "                w_out_v += edge[2] * h[edge[0]]\n",
        "                Hits_total_out_v += h[edge[0]]\n",
        "            for edge in G_hits.in_edges(u, data='weight'):\n",
        "                w_in_v += edge[2] * a[edge[1]]\n",
        "                Hits_total_in_v += a[edge[1]]\n",
        "            w_in[u] = w_in_v\n",
        "            w_out[u] = w_out_v\n",
        "            Hits_total_in[u] = Hits_total_in_v\n",
        "            Hits_total_out[u] = Hits_total_out_v\n",
        "        nx.set_node_attributes(G_hits, w_in, 'w_in')\n",
        "        nx.set_node_attributes(G_hits, w_out, 'w_out')\n",
        "        nx.set_node_attributes(G_hits, Hits_total_in, 'Hits_total_in')\n",
        "        nx.set_node_attributes(G_hits, Hits_total_out, 'Hits_total_out')\n",
        "\n",
        "        self.G_hits = G_hits\n",
        "\n",
        "    def predict_weight(self, u, v):\n",
        "\n",
        "        pred_w = 0\n",
        "        if self.G_hits.nodes[u]['Hits_total_out'] != 0:\n",
        "            pred_w += self.G_hits.nodes[u]['w_out'] / self.G_hits.nodes[u]['Hits_total_out']\n",
        "        if self.G_hits.nodes[v]['Hits_total_in'] != 0:\n",
        "            pred_w += self.G_hits.nodes[v]['w_in'] / self.G_hits.nodes[v]['Hits_total_in']\n",
        "        pred_w /= 2\n",
        "        return pred_w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av5_f5RfgCRN"
      },
      "source": [
        "def sample_edges(G, num_edges):\n",
        "    all_edges = list(nx.edges(G))\n",
        "    return random.sample(all_edges, num_edges)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkjQHzj9kZHO"
      },
      "source": [
        "def read_graph(filename):\n",
        "    G = nx.DiGraph()\n",
        "    f = open(f'/content/gdrive/MyDrive/{filename}', \"r\")\n",
        "    for l in f:\n",
        "        ls = l.strip().split(\",\")\n",
        "        G.add_edge(ls[0], ls[1], weight = float(ls[2])/10.0) # the weight should already be in the range of -1 to 1\n",
        "    f.close()\n",
        "    return G\n",
        "\n",
        "def run_prediction_algorithms(G, num_edges_to_test):\n",
        "    algorithms = ['Fairness_Goodness', 'Reciprocal', 'Bias_Deserve', 'Signed_Hits']\n",
        "    algorithm_type = ['fg', 'r', 'bd', 'sh']\n",
        "    G_copy = G.copy()\n",
        "    test_edges = sample_edges(G, num_edges_to_test)\n",
        "    true_weights = []\n",
        "    predicted_weights = {'fg': [], 'r': [], 'bd': [], 'sh': []}\n",
        "    rmse = {}\n",
        "    pcc = {}\n",
        "\n",
        "    for (u,v) in test_edges:\n",
        "        true_weights.append(G[u][v]['weight'])\n",
        "        G_copy.remove_edge(u, v)\n",
        "\n",
        "        for key in algorithm_type:\n",
        "            if key == 'fg':\n",
        "                method = Fairness_Goodness(G_copy)\n",
        "            elif key == 'r':\n",
        "                method = Reciprocal(G_copy)\n",
        "            elif key == 'bd':\n",
        "                method = Bias_Deserve(G_copy)\n",
        "            else:\n",
        "                method = Signed_Hits(G_copy)\n",
        "\n",
        "            predicted_weights[key].append(method.predict_weight(u, v))\n",
        "\n",
        "        G_copy.add_edge(u, v, weight=G[u][v]['weight'])\n",
        "\n",
        "    for t in algorithm_type:\n",
        "        rmse[t] = mean_squared_error(true_weights, predicted_weights[t], squared=False)\n",
        "        pcc[t] = pearsonr(true_weights, predicted_weights[t])[0]\n",
        "\n",
        "    rmse_stack = np.vstack(([rmse[x] for x in algorithm_type]))\n",
        "    pcc_stack = np.vstack(([pcc[x] for x in algorithm_type]))\n",
        "    df_rmse = pd.DataFrame(rmse_stack, index=algorithms, columns=['Value'])\n",
        "    df_pcc = pd.DataFrame(pcc_stack, index=algorithms, columns=['Value'])\n",
        "    print(df_rmse)\n",
        "    print(df_pcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjbgQnqpfVzQ"
      },
      "source": [
        "**Bitcoin OTC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL0au5ACkn3p",
        "outputId": "672ab5e5-8a3e-4028-c347-eff6b2bd1197"
      },
      "source": [
        "G_otc = read_graph('soc-sign-bitcoinotc.csv')\n",
        "run_prediction_algorithms(G_otc, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      Value\n",
            "Fairness_Goodness  0.330024\n",
            "Reciprocal         0.315943\n",
            "Bias_Deserve       0.338862\n",
            "Signed_Hits        0.299825\n",
            "                      Value\n",
            "Fairness_Goodness  0.388601\n",
            "Reciprocal         0.511097\n",
            "Bias_Deserve       0.369605\n",
            "Signed_Hits        0.542348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iea6zgXMfYsv"
      },
      "source": [
        "**Bitcoin Alpha**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiTq-SsNM8ac",
        "outputId": "224d51d2-f445-4208-f6b6-cd526e6aa0c7"
      },
      "source": [
        "G_alpha = read_graph('soc-sign-bitcoinalpha.csv')\n",
        "run_prediction_algorithms(G_alpha, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      Value\n",
            "Fairness_Goodness  0.294868\n",
            "Reciprocal         0.263249\n",
            "Bias_Deserve       0.299613\n",
            "Signed_Hits        0.288076\n",
            "                      Value\n",
            "Fairness_Goodness  0.268004\n",
            "Reciprocal         0.519646\n",
            "Bias_Deserve       0.262165\n",
            "Signed_Hits        0.253705\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}